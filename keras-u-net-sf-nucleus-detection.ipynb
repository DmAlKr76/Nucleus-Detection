{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n### Импорт библиотек","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport glob\nimport random\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport skimage.io                           #Used for imshow function\nimport skimage.transform                    #Used for resize function\nfrom skimage.morphology import label        #Used for Run-Length-Encoding RLE to create final submission\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import *\nimport torch\nfrom tensorflow.keras.layers import Input, Conv2D, Lambda, MaxPooling2D, Conv2DTranspose, concatenate, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.layers.experimental.preprocessing import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.optimizers.schedules import *\nfrom tensorflow.keras.backend import clear_session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:33:12.609710Z","iopub.execute_input":"2022-07-12T22:33:12.610208Z","iopub.status.idle":"2022-07-12T22:33:21.765879Z","shell.execute_reply.started":"2022-07-12T22:33:12.610102Z","shell.execute_reply":"2022-07-12T22:33:21.764912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SETUP","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = 'train/'\nTEST_PATH = 'test/'\n\nIMG_WIDTH       = 256\nIMG_HEIGHT      = 256\nIMG_SIZE        = 256\nIMG_CHANNELS    = 3\ninput_shape     = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)\n\nBATCH_SIZE      = 32\nNUM_EPOCHS      = 100\nLR              = 0.001\nvalidation_split= 0.1\n\nSEED = 42\nrandom.seed = SEED\nnp.random.seed(seed=SEED)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:21.767741Z","iopub.execute_input":"2022-07-12T22:33:21.768813Z","iopub.status.idle":"2022-07-12T22:33:21.777190Z","shell.execute_reply.started":"2022-07-12T22:33:21.768765Z","shell.execute_reply":"2022-07-12T22:33:21.774822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"# распаковываем данные\nimport zipfile\nfor name_data in ['test', 'train']:\n    tmp_zip = zipfile.ZipFile('../input/'+name_data+'.zip')\n    tmp_zip.extractall(name_data)\n    tmp_zip.close()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:21.779094Z","iopub.execute_input":"2022-07-12T22:33:21.779472Z","iopub.status.idle":"2022-07-12T22:33:27.034650Z","shell.execute_reply.started":"2022-07-12T22:33:21.779436Z","shell.execute_reply":"2022-07-12T22:33:27.033683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv')\nsample_submission.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:27.038286Z","iopub.execute_input":"2022-07-12T22:33:27.039163Z","iopub.status.idle":"2022-07-12T22:33:27.066119Z","shell.execute_reply.started":"2022-07-12T22:33:27.039121Z","shell.execute_reply":"2022-07-12T22:33:27.065167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sample_submission)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:27.067724Z","iopub.execute_input":"2022-07-12T22:33:27.068123Z","iopub.status.idle":"2022-07-12T22:33:27.075074Z","shell.execute_reply.started":"2022-07-12T22:33:27.068088Z","shell.execute_reply":"2022-07-12T22:33:27.074123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/train_labels.csv')\ntrain_labels.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:27.076294Z","iopub.execute_input":"2022-07-12T22:33:27.077048Z","iopub.status.idle":"2022-07-12T22:33:27.247702Z","shell.execute_reply.started":"2022-07-12T22:33:27.077010Z","shell.execute_reply":"2022-07-12T22:33:27.246816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:27.248936Z","iopub.execute_input":"2022-07-12T22:33:27.249528Z","iopub.status.idle":"2022-07-12T22:33:27.256082Z","shell.execute_reply.started":"2022-07-12T22:33:27.249489Z","shell.execute_reply":"2022-07-12T22:33:27.255060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_labels) - train_labels.ImageId.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:27.257590Z","iopub.execute_input":"2022-07-12T22:33:27.258267Z","iopub.status.idle":"2022-07-12T22:33:27.273065Z","shell.execute_reply.started":"2022-07-12T22:33:27.258228Z","shell.execute_reply":"2022-07-12T22:33:27.272165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сверяем по папкам","metadata":{}},{"cell_type":"code","source":"# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))\ntest_ids = next(os.walk(TEST_PATH))\n\nmask_count = 0\nfor train_id in train_ids[1]:\n    masks = next(os.walk(TRAIN_PATH + train_id + '/masks/'))[2]\n    mask_count += len(masks)\n\nprint('There are {} images.'.format(len(train_ids[1])))\nprint('There are {} masks.'.format(mask_count))\nprint('Approximately {} masks per image.'.format(mask_count // len(train_ids[1])))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:33:27.274181Z","iopub.execute_input":"2022-07-12T22:33:27.274846Z","iopub.status.idle":"2022-07-12T22:33:27.353029Z","shell.execute_reply.started":"2022-07-12T22:33:27.274808Z","shell.execute_reply":"2022-07-12T22:33:27.352056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"65 изображений на тесте и 670 на трейне.\n\nПодгрузим и посмотрим картинки.","metadata":{}},{"cell_type":"code","source":"def get_X_data(path, output_shape=(None, None)):\n    '''\n    Loads images from path/{id}/images/{id}.png into a numpy array\n    '''\n    img_paths = ['{0}/{1}/images/{1}.png'.format(path, id) for id in os.listdir(path)]\n    X_data = np.array([skimage.transform.resize(skimage.io.imread(path)[:,:,:3], \n                                                output_shape=output_shape, \n                                                mode='constant', \n                                                preserve_range=True) for path in img_paths], dtype=np.uint8)  #take only 3 channels/bands\n    \n    return X_data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:33:27.357233Z","iopub.execute_input":"2022-07-12T22:33:27.357476Z","iopub.status.idle":"2022-07-12T22:33:27.364097Z","shell.execute_reply.started":"2022-07-12T22:33:27.357454Z","shell.execute_reply":"2022-07-12T22:33:27.363131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Get training data\nX_train = get_X_data(TRAIN_PATH, output_shape=(IMG_HEIGHT,IMG_WIDTH))\nprint(X_train.shape, X_train.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:27.365538Z","iopub.execute_input":"2022-07-12T22:33:27.366195Z","iopub.status.idle":"2022-07-12T22:33:49.627199Z","shell.execute_reply.started":"2022-07-12T22:33:27.366159Z","shell.execute_reply":"2022-07-12T22:33:49.626265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_Y_data(path, output_shape=(None, None)):\n    '''\n    Loads and concatenates images from path/{id}/masks/{id}.png into a numpy array\n    '''\n    img_paths = [glob.glob('{0}/{1}/masks/*.png'.format(path, id)) for id in os.listdir(path)]\n    \n    Y_data = []\n    for i, img_masks in enumerate(img_paths):  #loop through each individual nuclei for an image and combine them together\n        masks = skimage.io.imread_collection(img_masks).concatenate()  #masks.shape = (num_masks, img_height, img_width)\n        mask = np.max(masks, axis=0)                                   #mask.shape = (img_height, img_width)\n        mask = skimage.transform.resize(mask, output_shape=output_shape+(1,), mode='constant', preserve_range=True)  #need to add an extra dimension so mask.shape = (img_height, img_width, 1)\n        Y_data.append(mask)\n    Y_data = np.array(Y_data, dtype=np.bool)\n    \n    return Y_data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:33:49.631404Z","iopub.execute_input":"2022-07-12T22:33:49.633659Z","iopub.status.idle":"2022-07-12T22:33:49.644386Z","shell.execute_reply.started":"2022-07-12T22:33:49.633605Z","shell.execute_reply":"2022-07-12T22:33:49.643454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Get training data labels\nY_train = get_Y_data(TRAIN_PATH, output_shape=(IMG_HEIGHT,IMG_WIDTH))\nprint(Y_train.shape, Y_train.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:33:49.646122Z","iopub.execute_input":"2022-07-12T22:33:49.646566Z","iopub.status.idle":"2022-07-12T22:34:51.137357Z","shell.execute_reply.started":"2022-07-12T22:33:49.646528Z","shell.execute_reply":"2022-07-12T22:34:51.136273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check training data\nf, axarr = plt.subplots(2,4)\nf.set_size_inches(20,10)\nix = random.randint(0, len(train_ids[1]))\naxarr[0,0].imshow(X_train[ix])\naxarr[0,1].imshow(np.squeeze(Y_train[ix]))\n\naxarr[0,2].imshow(X_train[ix])\naxarr[0,3].imshow(np.squeeze(Y_train[ix]))\n\naxarr[1,0].imshow(X_train[ix])\naxarr[1,1].imshow(np.squeeze(Y_train[ix]))\n\naxarr[1,2].imshow(X_train[ix])\naxarr[1,3].imshow(np.squeeze(Y_train[ix]))\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:34:51.138773Z","iopub.execute_input":"2022-07-12T22:34:51.144152Z","iopub.status.idle":"2022-07-12T22:34:52.215842Z","shell.execute_reply.started":"2022-07-12T22:34:51.144107Z","shell.execute_reply":"2022-07-12T22:34:52.214895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Подготовка данных","metadata":{}},{"cell_type":"markdown","source":"Аугментация","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:34:52.216868Z","iopub.execute_input":"2022-07-12T22:34:52.217202Z","iopub.status.idle":"2022-07-12T22:35:12.026633Z","shell.execute_reply.started":"2022-07-12T22:34:52.217170Z","shell.execute_reply":"2022-07-12T22:35:12.025507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:12.029717Z","iopub.execute_input":"2022-07-12T22:35:12.030110Z","iopub.status.idle":"2022-07-12T22:35:12.447141Z","shell.execute_reply.started":"2022-07-12T22:35:12.030073Z","shell.execute_reply":"2022-07-12T22:35:12.446127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n#     A.OneOf([\n#         A.CenterCrop(height=224, width=200),\n#         A.CenterCrop(height=200, width=224),\n#     ],p=0.5),\n#     A.OneOf([\n#         A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n#         A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n#     ],p=0.5),\n#     A.GaussianBlur(p=0.05),\n#     A.HueSaturationValue(p=0.5),\n#     A.RGBShift(),\n#     A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n#     A.Resize(IMG_SIZE, IMG_SIZE)\n])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:12.448502Z","iopub.execute_input":"2022-07-12T22:35:12.449923Z","iopub.status.idle":"2022-07-12T22:35:12.457162Z","shell.execute_reply.started":"2022-07-12T22:35:12.449864Z","shell.execute_reply":"2022-07-12T22:35:12.456234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n                                   transform,\n                                   #rescale = 1/255,\n                                   validation_split = validation_split,\n                                   )\n\ntest_datagen = ImageDataGenerator(\n                                    #rescale = 1/255\n                                 )","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:12.459424Z","iopub.execute_input":"2022-07-12T22:35:12.460924Z","iopub.status.idle":"2022-07-12T22:35:12.471385Z","shell.execute_reply.started":"2022-07-12T22:35:12.460897Z","shell.execute_reply":"2022-07-12T22:35:12.470442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen.fit(X_train)\n\ntrain_generator = datagen.flow(\n    X_train, \n    Y_train, \n    batch_size=BATCH_SIZE,\n    subset='training')\n\ntest_generator = datagen.flow(\n    X_train, \n    Y_train, \n    batch_size=8,\n    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:12.472722Z","iopub.execute_input":"2022-07-12T22:35:12.473698Z","iopub.status.idle":"2022-07-12T22:35:15.560015Z","shell.execute_reply.started":"2022-07-12T22:35:12.473662Z","shell.execute_reply":"2022-07-12T22:35:15.558976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axarr = plt.subplots(2,4)\nf.set_size_inches(20,10)\n\nindex = random.randint(0, len(train_ids[1]))\n\naxarr[0,0].imshow(X_train[index])\naxarr[0,1].imshow(np.squeeze(Y_train[index]))\n\naxarr[0,2].imshow(X_train[index])\naxarr[0,3].imshow(np.squeeze(Y_train[index]))\n\nindex = random.randint(0, len(train_ids[1]))\n\naxarr[1,0].imshow(X_train[index])\naxarr[1,1].imshow(np.squeeze(Y_train[index]))\n\naxarr[1,2].imshow(X_train[index])\naxarr[1,3].imshow(np.squeeze(Y_train[index]))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:15.561565Z","iopub.execute_input":"2022-07-12T22:35:15.561924Z","iopub.status.idle":"2022-07-12T22:35:16.642663Z","shell.execute_reply.started":"2022-07-12T22:35:15.561888Z","shell.execute_reply":"2022-07-12T22:35:16.641748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Build model","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Построим U-Net model, по мотивам [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) и близко к этому [репозиторию](https://github.com/jocicmarko/ultrasound-nerve-segmentation) из Kaggle Ultrasound Nerve Segmentation competition.\n\n![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)","metadata":{}},{"cell_type":"markdown","source":"Функция ошибки - составной лосс (focal+dice)","metadata":{}},{"cell_type":"code","source":"# def combo_loss(y_real, y_pred, eps = 1e-8, gamma = 2):\n#   y_pred = torch.sigmoid(y_pred)\n#   pt = y_real*y_pred+(1-y_real)*(1-y_pred)\n#   focal = (-1*((1-pt)**gamma)*torch.log(pt+eps)).mean()\n#   num = 2*torch.sum((y_real*y_pred),dim=(1,2,3))\n#   den =  torch.sum((y_real+y_pred),dim=(1,2,3))\n#   dice = (1 - num / (den + eps)).mean()\n#   return focal + dice","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:16.644105Z","iopub.execute_input":"2022-07-12T22:35:16.644673Z","iopub.status.idle":"2022-07-12T22:35:16.649305Z","shell.execute_reply.started":"2022-07-12T22:35:16.644636Z","shell.execute_reply":"2022-07-12T22:35:16.648236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build U-Net model\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n#c5 = BatchNormalization() (c5)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\noptimizer = Adam(ExponentialDecay(LR, 100, 0.9))\nmodel.compile(\n    optimizer=optimizer, \n    #loss=combo_loss, \n    loss='binary_crossentropy',\n    #loss=tf.keras.metrics.binary_focal_crossentropy,\n    #loss = 'sparse_categorical_crossentropy',\n    metrics='accuracy'\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:16.651123Z","iopub.execute_input":"2022-07-12T22:35:16.651567Z","iopub.status.idle":"2022-07-12T22:35:22.514340Z","shell.execute_reply.started":"2022-07-12T22:35:16.651527Z","shell.execute_reply":"2022-07-12T22:35:22.513382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5',\n                             monitor='val_accuracy',\n                             verbose=1,\n                             mode='max',\n                             save_best_only=True)\nearly_stopping = EarlyStopping(monitor='accuracy', \n                               patience=5, \n                               verbose = 1, \n                               restore_best_weights=True)\ncallbacks_list = [checkpoint, \n                  early_stopping\n                 ]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:22.515820Z","iopub.execute_input":"2022-07-12T22:35:22.516162Z","iopub.status.idle":"2022-07-12T22:35:22.522185Z","shell.execute_reply.started":"2022-07-12T22:35:22.516126Z","shell.execute_reply":"2022-07-12T22:35:22.521123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit model\nhistory = model.fit(\n                    train_generator,\n                    #test_generator,\n                    #X_train, \n                    #Y_train, \n                    steps_per_epoch = len(train_generator), \n                    validation_data = test_generator, \n                    validation_steps = len(test_generator), \n                    #validation_split=validation_split,\n                    #batch_size=BATCH_SIZE,\n                    epochs = NUM_EPOCHS, \n                    callbacks = callbacks_list,\n                    verbose=2\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:35:22.523871Z","iopub.execute_input":"2022-07-12T22:35:22.524715Z","iopub.status.idle":"2022-07-12T22:40:46.096980Z","shell.execute_reply.started":"2022-07-12T22:35:22.524678Z","shell.execute_reply":"2022-07-12T22:40:46.096013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('keras_unet.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:46.103896Z","iopub.execute_input":"2022-07-12T22:40:46.106457Z","iopub.status.idle":"2022-07-12T22:40:46.320507Z","shell.execute_reply.started":"2022-07-12T22:40:46.106415Z","shell.execute_reply":"2022-07-12T22:40:46.319525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_history(history):\n    # validation losses\n    val_loss = history.history['val_loss']\n    loss = history.history['loss']\n\n    plt.title('Loss')\n    plt.plot(val_loss, 'r', loss, 'b')\n    plt.show()\n    \nplot_loss_history(history)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:40:46.327507Z","iopub.execute_input":"2022-07-12T22:40:46.329920Z","iopub.status.idle":"2022-07-12T22:40:46.503040Z","shell.execute_reply.started":"2022-07-12T22:40:46.329881Z","shell.execute_reply":"2022-07-12T22:40:46.502154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:46.505860Z","iopub.execute_input":"2022-07-12T22:40:46.506144Z","iopub.status.idle":"2022-07-12T22:40:46.867179Z","shell.execute_reply.started":"2022-07-12T22:40:46.506118Z","shell.execute_reply":"2022-07-12T22:40:46.866205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Make predictions","metadata":{}},{"cell_type":"code","source":"# Use model to predict train labels\nmodel = load_model('keras_unet.h5',)\nY_predict = model.predict(X_train, verbose=1)\nY_predict.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:46.872734Z","iopub.execute_input":"2022-07-12T22:40:46.873002Z","iopub.status.idle":"2022-07-12T22:40:49.729588Z","shell.execute_reply.started":"2022-07-12T22:40:46.872976Z","shell.execute_reply":"2022-07-12T22:40:49.728568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check predict data\nf, axarr = plt.subplots(2,3)\nf.set_size_inches(20,10)\nix = random.randint(0, len(train_ids[1]))\naxarr[0,0].imshow(X_train[ix])\naxarr[0,0].set_title('Microscope')\naxarr[0,1].imshow(np.squeeze(Y_predict[ix]))\naxarr[0,1].set_title('\"Predicted\" Masks')\naxarr[0,2].imshow(np.squeeze(Y_train[ix]))\naxarr[0,2].set_title('\"GroundTruth\" Masks')\n\naxarr[1,0].imshow(X_train[ix])\naxarr[1,0].set_title('Microscope')\naxarr[1,1].imshow(np.squeeze(Y_predict[ix]))\naxarr[1,1].set_title('\"Predicted\" Masks')\naxarr[1,2].imshow(np.squeeze(Y_train[ix]))\naxarr[1,2].set_title('\"GroundTruth\" Masks')\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:40:49.731113Z","iopub.execute_input":"2022-07-12T22:40:49.731495Z","iopub.status.idle":"2022-07-12T22:40:50.454798Z","shell.execute_reply.started":"2022-07-12T22:40:49.731458Z","shell.execute_reply":"2022-07-12T22:40:50.453849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get test data\nX_test = get_X_data(TEST_PATH, output_shape=(IMG_HEIGHT,IMG_WIDTH))\n\n# Use model to predict test labels\nY_hat = model.predict(X_test, verbose=1)\nY_hat.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:50.456074Z","iopub.execute_input":"2022-07-12T22:40:50.456899Z","iopub.status.idle":"2022-07-12T22:40:52.866364Z","shell.execute_reply.started":"2022-07-12T22:40:50.456855Z","shell.execute_reply":"2022-07-12T22:40:52.865283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = random.randint(0, len(test_ids[1]))\nprint(X_test[idx].shape)\nskimage.io.imshow(X_test[idx])\nplt.show()\nskimage.io.imshow(Y_hat[idx][:,:,0])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:40:52.867755Z","iopub.execute_input":"2022-07-12T22:40:52.868139Z","iopub.status.idle":"2022-07-12T22:40:53.304041Z","shell.execute_reply.started":"2022-07-12T22:40:52.868099Z","shell.execute_reply":"2022-07-12T22:40:53.303012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Encode and Submit","metadata":{}},{"cell_type":"code","source":"# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:40:53.306791Z","iopub.execute_input":"2022-07-12T22:40:53.307059Z","iopub.status.idle":"2022-07-12T22:40:53.313600Z","shell.execute_reply.started":"2022-07-12T22:40:53.307033Z","shell.execute_reply":"2022-07-12T22:40:53.312549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"мы ресайзили картинку до 256х256, но чтоб верно предсказать, нам нужно сделать маску под размер изначальной картинки","metadata":{}},{"cell_type":"code","source":"# Upsample Y_hat back to the original X_test size (height and width)\nY_hat_upsampled = []\nfor i, test_id in enumerate(os.listdir(TEST_PATH)):  #loop through test_ids in the test_path\n    img = skimage.io.imread('{0}/{1}/images/{1}.png'.format(TEST_PATH, test_id))  #read original test image directly from path\n    img_upscaled = skimage.transform.resize(Y_hat[i], (img.shape[0], img.shape[1]), mode='constant', preserve_range=True)  #upscale Y_hat image according to original test image\n    Y_hat_upsampled.append(img_upscaled)   #append upscaled image to Y_hat_upsampled\nlen(Y_hat_upsampled)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:53.315350Z","iopub.execute_input":"2022-07-12T22:40:53.315792Z","iopub.status.idle":"2022-07-12T22:40:54.492271Z","shell.execute_reply.started":"2022-07-12T22:40:53.315744Z","shell.execute_reply":"2022-07-12T22:40:54.491193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Осталось закодировать нашу маску","metadata":{}},{"cell_type":"code","source":"# Apply Run-Length Encoding on our Y_hat_upscaled\nnew_test_ids = []\nrles = []\nfor n, id_ in enumerate(os.listdir(TEST_PATH)):\n    rle = list(prob_to_rles(Y_hat_upsampled[n]))\n    rles.extend(rle)\n    new_test_ids.extend([id_] * len(rle))\nlen(new_test_ids)  #note that for each test_image, we can have multiple entries of encoded pixels","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:54.497298Z","iopub.execute_input":"2022-07-12T22:40:54.497695Z","iopub.status.idle":"2022-07-12T22:40:55.833897Z","shell.execute_reply.started":"2022-07-12T22:40:54.497657Z","shell.execute_reply":"2022-07-12T22:40:55.832928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission DataFrame\nsub = pd.DataFrame()\nsub['ImageId'] = new_test_ids\nsub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:55.835471Z","iopub.execute_input":"2022-07-12T22:40:55.835862Z","iopub.status.idle":"2022-07-12T22:40:55.929287Z","shell.execute_reply.started":"2022-07-12T22:40:55.835825Z","shell.execute_reply":"2022-07-12T22:40:55.928398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:55.930765Z","iopub.execute_input":"2022-07-12T22:40:55.931123Z","iopub.status.idle":"2022-07-12T22:40:55.941525Z","shell.execute_reply.started":"2022-07-12T22:40:55.931086Z","shell.execute_reply":"2022-07-12T22:40:55.940243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sub)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T22:40:55.943151Z","iopub.execute_input":"2022-07-12T22:40:55.944240Z","iopub.status.idle":"2022-07-12T22:40:55.951626Z","shell.execute_reply.started":"2022-07-12T22:40:55.944185Z","shell.execute_reply":"2022-07-12T22:40:55.950506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean Folder\n# import shutil\n# shutil.rmtree('train')\n# shutil.rmtree('test')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-12T22:40:55.952617Z","iopub.execute_input":"2022-07-12T22:40:55.954444Z","iopub.status.idle":"2022-07-12T22:40:55.960126Z","shell.execute_reply.started":"2022-07-12T22:40:55.954404Z","shell.execute_reply":"2022-07-12T22:40:55.959181Z"},"trusted":true},"execution_count":null,"outputs":[]}]}